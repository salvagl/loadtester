# FASE 3 - Plan de Continuaci√≥n para Ma√±ana

**Fecha de Creaci√≥n:** 2025-01-08
**Estado Actual:** üü° EN PROGRESO (50% completado)
**Pr√≥xima Sesi√≥n:** Continuar implementaci√≥n completa

---

## üìä Estado Actual al Final de Hoy

### Tests de Integraci√≥n Implementados

| Archivo | Tests | Pasando | Fallando | Estado |
|---------|-------|---------|----------|--------|
| `test_openapi_flow.py` | 11 | 11 | 0 | ‚úÖ 100% |
| `test_scenario_flow.py` | 11 | 7 | 4 | üü° 63.6% |
| `test_job_execution_flow.py` | 14 | 14 | 0 | ‚úÖ 100% |
| **TOTAL ACTUAL** | **36** | **32** | **4** | **88.9%** |

### Comando para Ejecutar Tests Actuales
```bash
cd "g:/Mi unidad/PSU-IA/Q2/TF1/src/backend"
source ../.venv/Scripts/activate
python -m pytest tests/integration/ -v
```

### Resultado Actual
```
32 passed, 4 failed, 7 warnings in 19.89s
```

---

## üêõ PASO 1: Corregir Tests Fallidos (5-10 minutos)

### test_scenario_flow.py - 4 Correcciones Necesarias

#### Correcci√≥n 1: test_complete_scenario_generation_flow (l√≠nea ~43)

**Ubicaci√≥n:** `tests/integration/test_scenario_flow.py:43`

**Error:**
```python
TypeError: create_mock_endpoint_post() got an unexpected keyword argument 'endpoint_path'
```

**C√≥digo Actual (INCORRECTO):**
```python
endpoint = create_mock_endpoint_post(
    api_id=created_api.api_id,
    endpoint_path="/users",  # ‚ùå NO EXISTE
    http_method="POST"       # ‚ùå NO EXISTE
)
```

**Correcci√≥n:**
```python
endpoint = create_mock_endpoint_post(
    api_id=created_api.api_id
)
```

---

#### Correcciones 2, 3, 4: generate_mock_data() - Par√°metro Incorrecto

**Tests Afectados:**
- `test_scenario_generation_with_custom_data` (l√≠nea ~166)
- `test_scenario_mock_data_sufficient_count` (l√≠nea ~271)
- `test_scenario_data_uniqueness` (l√≠nea ~324)

**Error:**
```python
TypeError: MockDataGeneratorService.generate_mock_data() got an unexpected keyword argument 'endpoint_schema'
```

**C√≥digo Actual (INCORRECTO):**
```python
mock_data = await mock_generator.generate_mock_data(
    endpoint=created_endpoint,
    endpoint_schema=schema,  # ‚ùå PAR√ÅMETRO INCORRECTO
    count=100
)
```

**Correcci√≥n (aplicar en las 3 ubicaciones):**
```python
mock_data = await mock_generator.generate_mock_data(
    endpoint=created_endpoint,
    schema=schema,  # ‚úÖ CORRECTO
    count=100
)
```

---

### Verificaci√≥n Post-Correcci√≥n

**Comando:**
```bash
python -m pytest tests/integration/test_scenario_flow.py -v
```

**Resultado Esperado:**
```
11 passed in ~XX seconds
```

**Total tras correcciones:**
```
36 passed, 0 failed
```

---

## üöÄ PASO 2: Implementar Archivos Faltantes

### Archivos Pendientes Seg√∫n Estrategia Original

Referencia: `docs/testing_strategy.md` - Secci√≥n "4. TESTS DE INTEGRACI√ìN"

---

### Archivo 4: test_report_generation_flow.py

**Ubicaci√≥n:** `tests/integration/test_report_generation_flow.py`

**Referencia Estrategia:** L√≠neas 418-440 de `testing_strategy.md`

**Tests a Implementar (~10-15 tests):**

```python
# Tests Principales
1. test_complete_report_generation_flow()
   # Results ‚Üí Generate PDF ‚Üí Verify file exists ‚Üí Verify content

2. test_report_with_multiple_endpoints()
   # Reporte con resultados de m√∫ltiples endpoints

3. test_report_with_degradation_detected()
   # Reporte que incluye detecci√≥n de degradaci√≥n

4. test_report_with_missing_data()
   # Manejo de datos faltantes en resultados

5. test_report_file_naming()
   # Verificar convenci√≥n de nombres de archivo

# Tests de Clasificaci√≥n de Performance
6. test_report_performance_classification_excellent()
7. test_report_performance_classification_good()
8. test_report_performance_classification_acceptable()
9. test_report_performance_classification_poor()

# Tests de Contenido PDF
10. test_report_contains_metrics_table()
11. test_report_contains_summary_section()
12. test_report_contains_recommendations()

# Edge Cases
13. test_report_with_null_timestamps()
14. test_report_with_zero_requests()
```

**Componentes a Integrar:**
- `ReportGeneratorService` (from `loadtester.infrastructure.external.pdf_generator_service`)
- `TestResultRepository`
- `JobRepository`
- Directorio temporal para PDFs (fixture: `tmp_path`)

**Imports Necesarios:**
```python
from loadtester.infrastructure.external.pdf_generator_service import ReportGeneratorService
from loadtester.infrastructure.repositories.test_result_repository import TestResultRepository
from loadtester.infrastructure.repositories.job_repository import JobRepository
from tests.fixtures.mock_data import create_mock_test_result, create_mock_job
import os
from pathlib import Path
```

---

### Archivo 5: test_api_endpoints.py

**Ubicaci√≥n:** `tests/integration/test_api_endpoints.py`

**Referencia Estrategia:** L√≠neas 442-483 de `testing_strategy.md`

**Tests a Implementar (~15-20 tests):**

```python
# POST /api/v1/load-test
1. test_create_load_test_success()
2. test_create_load_test_invalid_config()
3. test_create_load_test_invalid_openapi_spec()
4. test_create_load_test_concurrent_limit()

# GET /api/v1/status/{job_id}
5. test_get_job_status_pending()
6. test_get_job_status_running()
7. test_get_job_status_finished()
8. test_get_job_status_failed()
9. test_get_job_status_not_found()
10. test_get_job_status_with_progress()

# GET /api/v1/report/{job_id}
11. test_download_report_success()
12. test_download_report_not_ready()
13. test_download_report_not_found()

# POST /api/v1/openapi/validate
14. test_validate_openapi_spec_valid_json()
15. test_validate_openapi_spec_valid_yaml()
16. test_validate_openapi_spec_invalid()

# POST /api/v1/openapi/parse
17. test_parse_openapi_spec_success()
18. test_parse_openapi_spec_invalid()

# GET /api/v1/health
19. test_health_check()

# Error Handling
20. test_endpoint_validation_errors()
```

**Componentes a Integrar:**
- FastAPI `TestClient`
- Todos los routers de `loadtester.presentation.api.v1`
- Mocks de servicios (K6Runner, etc.)

**Imports Necesarios:**
```python
from fastapi.testclient import TestClient
from loadtester.presentation.api.main import app
from unittest.mock import AsyncMock, patch
import json
```

**Fixture Necesaria:**
```python
@pytest.fixture
def client():
    """FastAPI test client."""
    return TestClient(app)
```

---

### Archivo 6: test_database_integration.py

**Ubicaci√≥n:** `tests/integration/test_database_integration.py`

**Referencia Estrategia:** L√≠neas 485-511 de `testing_strategy.md`

**Tests a Implementar (~10-15 tests):**

```python
# Relaciones entre entidades
1. test_api_endpoint_relationship()
   # API tiene m√∫ltiples Endpoints

2. test_endpoint_scenario_relationship()
   # Endpoint tiene m√∫ltiples Scenarios

3. test_scenario_execution_relationship()
   # Scenario tiene m√∫ltiples Executions

4. test_execution_result_relationship()
   # Execution tiene un Result

5. test_job_complete_chain()
   # Job ‚Üí API ‚Üí Endpoints ‚Üí Scenarios ‚Üí Executions ‚Üí Results

# Cascadas y Deletes
6. test_delete_api_cascades_endpoints()
7. test_delete_endpoint_cascades_scenarios()
8. test_delete_scenario_cascades_executions()

# Transacciones
9. test_transaction_rollback_on_error()
10. test_transaction_commit_on_success()

# Queries complejas
11. test_get_all_results_for_job()
12. test_get_running_jobs_query()
13. test_get_scenarios_by_endpoint()

# Integridad Referencial
14. test_foreign_key_constraints()
15. test_unique_constraints()
```

**Componentes a Integrar:**
- Todos los repositorios
- Todas las entidades de dominio
- Verificaci√≥n de cascadas y constraints

**Imports Necesarios:**
```python
from loadtester.domain.entities.domain_entities import (
    API, Endpoint, TestScenario, TestExecution, TestResult, Job
)
from loadtester.infrastructure.repositories import (
    APIRepository, EndpointRepository, TestScenarioRepository,
    TestExecutionRepository, TestResultRepository, JobRepository
)
from sqlalchemy.exc import IntegrityError
import pytest
```

---

## üìã Orden de Implementaci√≥n Recomendado

### Sesi√≥n Ma√±ana (2-3 horas)

**Prioridad 1: Correcciones (10 min)**
1. ‚úÖ Corregir 4 tests en `test_scenario_flow.py`
2. ‚úÖ Verificar 36/36 passing

**Prioridad 2: Report Generation (45 min)**
3. ‚úÖ Implementar `test_report_generation_flow.py` (10-15 tests)
4. ‚úÖ Ejecutar y corregir errores

**Prioridad 3: Database Integration (30 min)**
5. ‚úÖ Implementar `test_database_integration.py` (10-15 tests)
6. ‚úÖ Ejecutar y corregir errores

**Prioridad 4: API Endpoints (1 hora)**
7. ‚úÖ Implementar `test_api_endpoints.py` (15-20 tests)
8. ‚úÖ Configurar TestClient y mocks
9. ‚úÖ Ejecutar y corregir errores

**Prioridad 5: Validaci√≥n Final (15 min)**
10. ‚úÖ Ejecutar suite completa de integraci√≥n
11. ‚úÖ Generar reporte de cobertura
12. ‚úÖ Actualizar documentaci√≥n final

---

## üéØ Objetivo Final

### Meta de Tests
- **Archivos:** 6/6 (100%)
- **Tests Totales:** 70-85 tests de integraci√≥n
- **Pass Rate:** 100%
- **Tiempo Ejecuci√≥n:** < 60 segundos

### Meta de Cobertura
- ‚úÖ OpenAPI Flow (100%)
- ‚úÖ Scenario Flow (100%)
- ‚úÖ Job Execution Flow (100%)
- ‚úÖ Report Generation Flow (100%)
- ‚úÖ API REST Endpoints (100%)
- ‚úÖ Database Integration (100%)

### Comandos Finales

**Ejecutar todos los tests de integraci√≥n:**
```bash
python -m pytest tests/integration/ -v
```

**Generar reporte de cobertura:**
```bash
python -m pytest tests/integration/ --cov=loadtester --cov-report=html --cov-report=term
```

**Ver cobertura:**
```bash
# El reporte HTML estar√° en: htmlcov/index.html
```

---

## üìö Referencias Importantes

### Documentos de Estrategia
- **Estrategia completa:** `docs/testing_strategy.md`
- **Fixtures disponibles:** `tests/fixtures/mock_data.py`
- **Configuraci√≥n pytest:** `pytest.ini`
- **Tests unitarios (referencia):** `tests/unit/`

### Ubicaciones de C√≥digo de Producci√≥n
- **Servicios:** `loadtester/domain/services/`
- **Repositorios:** `loadtester/infrastructure/repositories/`
- **Entidades:** `loadtester/domain/entities/domain_entities.py`
- **API Endpoints:** `loadtester/presentation/api/v1/`
- **PDF Generator:** `loadtester/infrastructure/external/pdf_generator_service.py`

### Fixtures Globales (conftest.py)
```python
@pytest.fixture
async def db_session():
    """SQLite async session en memoria"""

@pytest.fixture
def mock_ai_client():
    """Mock de AI client"""

@pytest.fixture
def degradation_settings():
    """Configuraci√≥n de degradaci√≥n"""
```

---

## ‚úÖ Checklist para Ma√±ana

### Pre-Inicio
- [ ] Activar venv: `source ../.venv/Scripts/activate`
- [ ] Verificar estado actual: `python -m pytest tests/integration/ -v`
- [ ] Confirmar 32/36 passing

### Correcciones
- [ ] Fix test_complete_scenario_generation_flow
- [ ] Fix test_scenario_generation_with_custom_data
- [ ] Fix test_scenario_mock_data_sufficient_count
- [ ] Fix test_scenario_data_uniqueness
- [ ] Verificar 36/36 passing

### Implementaciones
- [ ] Crear test_report_generation_flow.py
- [ ] Crear test_database_integration.py
- [ ] Crear test_api_endpoints.py
- [ ] Ejecutar cada archivo individualmente
- [ ] Corregir errores encontrados

### Validaci√≥n Final
- [ ] Ejecutar suite completa
- [ ] Generar reporte de cobertura
- [ ] Verificar 70-85 tests passing
- [ ] Documentar resultados finales

---

## üìä M√©tricas Actuales vs Objetivo

| M√©trica | Actual | Objetivo | Progreso |
|---------|--------|----------|----------|
| Archivos | 3/6 | 6/6 | 50% |
| Tests | 36 | 70-85 | 42-51% |
| Passing | 32 | 70-85 | 38-46% |
| Pass Rate | 88.9% | 100% | 88.9% |

---

## üöÄ Motivaci√≥n

**Ya hemos logrado:**
- ‚úÖ 193 tests unitarios (100% passing)
- ‚úÖ 32 tests de integraci√≥n (funcionando)
- ‚úÖ Infraestructura de testing robusta
- ‚úÖ Flujos cr√≠ticos validados (OpenAPI, Jobs)

**Ma√±ana completaremos:**
- üéØ 100% de la estrategia de FASE 3
- üéØ ~270-280 tests totales en el proyecto
- üéØ Cobertura completa de flujos end-to-end
- üéØ Proyecto con testing profesional de producci√≥n

---

**Creado:** 2025-01-08
**Para continuar:** 2025-01-09
**Tiempo estimado ma√±ana:** 2-3 horas
**Dificultad:** Media (infraestructura ya est√° lista)

¬°Todo listo para completar FASE 3 al 100% ma√±ana! üöÄ
